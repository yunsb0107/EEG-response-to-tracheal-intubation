{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import vitaldb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sig\n",
    "from scipy.signal import welch, savgol_filter\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import simps\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "import neurokit2 as nk\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "def consecutive(data, stepsize=0, threshold=100):\n",
    "    con_list = np.split(data, np.where(np.diff(data) != stepsize)[0]+1)\n",
    "    con_count = [d for d in con_list if len(d)>threshold]\n",
    "    return con_count\n",
    "\n",
    "# searching available cases & collect intubation information\n",
    "available_casedf = pd.read_csv(\"https://api.vitaldb.net/cases\")\n",
    "cases = available_casedf['caseid'].values\n",
    "evtdf = pd.read_csv('Supplementary Table 1.csv', header=3)\n",
    "\n",
    "# parameters for extraction\n",
    "datatrks = ['EVENT', 'NIBP_SBP','ART_SBP','HR','PPF20_CE','RFTN20_CE','EEG1_WAV', 'BIS'] \n",
    "eegcol = 'EEG1_WAV'\n",
    "hrcol = 'HR'\n",
    "ppfcol = 'PPF20_CE'\n",
    "remicol = 'RFTN20_CE'\n",
    "\n",
    "# settings for extraction \n",
    "MAX = 9999\n",
    "SRATE = 128\n",
    "SEGLENSEC = 30\n",
    "OFFSETSEC = 10\n",
    "SEGLEN = int(SRATE * SEGLENSEC)\n",
    "SLIDE = int(SRATE * OFFSETSEC)\n",
    "DELTA_LOW = 1\n",
    "DELTA_HIGH = 4\n",
    "THETA_LOW = 4\n",
    "THETA_HIGH = 8\n",
    "ALPHA_LOW = 8\n",
    "ALPHA_HIGH = 12\n",
    "BETA_LOW = 12\n",
    "BETA_HIGH = 25\n",
    "\n",
    "prewindow = int(1 * 60 * SRATE) # analyze 1 minute before intubation\n",
    "pstwindow = int(1 * 60 * SRATE) # analyze 1 minute after intubation\n",
    "nibp_window = int(2.5 * 60 * SRATE) # exception for non-invasive blood pressure measurements taken at 2.5 minute intervals\n",
    "\n",
    "\n",
    "### parameters for result\n",
    "freqs = np.linspace(0.0, 64.0, int(64*SEGLENSEC+1))\n",
    "freqcols = list(map(lambda f: str(round(f, 2)) + 'Hz', freqs))\n",
    "norm_freqcols = list(map(lambda f: 'norm_'+str(round(f, 2)) + 'Hz', freqs))\n",
    "filecols = ['vitalfile', 'intu_dur','hr', 'bp','hr_change', 'bp_change', 'timing', 'PPF20_CE','RFTN20_CE', 'BIS',\\\n",
    "            'total', 'delta', 'theta', 'alpha', 'beta', 'delta_rel', 'theta_rel', 'alpha_rel', 'beta_rel',\\\n",
    "                  *freqcols, *norm_freqcols]\n",
    "\n",
    "RESULT_FILE = f'result.csv'\n",
    "with open(RESULT_FILE, 'a', newline='', encoding='utf-8-sig') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow(filecols)\n",
    "\n",
    "\n",
    "### EEG analysis\n",
    "def process_eeg(eegdf, ix, window, seg, slide, prev_row):    \n",
    "    for i in range(0, window-seg, slide):\n",
    "        temp = []  \n",
    "\n",
    "        small_eeg = eegdf.iloc[ix+i:ix+i+seg]\n",
    "\n",
    "        if len(small_eeg) < seg/2:\n",
    "            continue\n",
    "\n",
    "        if small_eeg.isnull().mean()>0.05:\n",
    "            continue\n",
    "\n",
    "        small_eeg = small_eeg.fillna(method='ffill', axis=0).fillna(method='bfill', axis=0).values   \n",
    "\n",
    "        small_eeg -= savgol_filter(small_eeg, 51, 3)\n",
    "\n",
    "        nall = len(consecutive(small_eeg, stepsize=0, threshold=SRATE*1))\n",
    "        if nall > 1:\n",
    "            continue\n",
    "\n",
    "        psd, freqs = psd_array_multitaper(small_eeg, SRATE, adaptive=True, normalization='full', verbose=0)  # https://raphaelvallat.com/bandpower.html\n",
    "        fres = freqs[1] - freqs[0]\n",
    "    \n",
    "        total = simps(psd, dx=fres)      \n",
    "        \n",
    "        delta = simps(psd[(freqs >= DELTA_LOW) & (freqs <= DELTA_HIGH)], dx=fres)\n",
    "        theta = simps(psd[(freqs >= THETA_LOW) & (freqs <= THETA_HIGH)], dx=fres)\n",
    "        alpha = simps(psd[(freqs >= ALPHA_LOW) & (freqs <= ALPHA_HIGH)], dx=fres)\n",
    "        beta = simps(psd[(freqs >= BETA_LOW) & (freqs <= BETA_HIGH)], dx=fres)\n",
    "    \n",
    "        delta_rel = 10*np.log(delta/total) \n",
    "        theta_rel = 10*np.log(theta/total) \n",
    "        alpha_rel = 10*np.log(alpha/total) \n",
    "        beta_rel = 10*np.log(beta/total) \n",
    "        total = simps(psd, dx=fres)\n",
    "\n",
    "        bandpower = {'total':total,'delta':delta,'theta':theta,'alpha':alpha,'beta':beta,\\\n",
    "                    'delta_rel':delta_rel,'theta_rel':theta_rel,'alpha_rel':alpha_rel,'beta_rel':beta_rel, 'i':i}\n",
    "     \n",
    "\n",
    "        norm_psd = psd /np.sum(psd)\n",
    "        norm_psd = 10* np.log(norm_psd)\n",
    "\n",
    "        power_dict = {f: p for f, p in zip(freqcols, psd)}\n",
    "        norm_power_dict = {'norm_'+f: p for f, p in zip(freqcols, norm_psd)}\n",
    "\n",
    "        temp.append({**bandpower, **power_dict, **norm_power_dict})\n",
    "\n",
    "        temp = pd.DataFrame(temp)\n",
    "\n",
    "        if np.isnan(delta):\n",
    "            continue\n",
    "\n",
    "        row = {**prev_row, **temp}     \n",
    "        \n",
    "        rowdf = pd.DataFrame(row, columns=filecols, index=[0])\n",
    "        \n",
    "        with open(RESULT_FILE, 'a', newline='', encoding='utf-8-sig') as f:\n",
    "            wr = csv.writer(f)\n",
    "            wr.writerow(rowdf.values[0])\n",
    "       \n",
    "\n",
    "\n",
    "for icase in cases[:MAX]:\n",
    "\n",
    "    vf = vitaldb.load_case(icase, datatrks, 1 / SRATE)\n",
    "    file = '{:04d}'.format(icase) + '.vital'\n",
    "    df = pd.DataFrame(vf, columns=datatrks) #vf.to_pandas(datatrks, 1 / SRATE) \n",
    "\n",
    "    evt1ix, evt2ix = np.nan, np.nan\n",
    "\n",
    "    try:\n",
    "        evt1ix = evtdf.loc[evtdf['caseid']==file]['initiation'].values[0]\n",
    "        evt2ix = evtdf.loc[evtdf['caseid']==file]['completion'].values[0]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if np.isnan(evt1ix)|np.isnan(evt2ix):        \n",
    "        continue\n",
    "    \n",
    "    intudur = (evt2ix-evt1ix)/SRATE    \n",
    "\n",
    "    # extract heart rate\n",
    "    pre_hr, pst_hr = np.nan, np.nan\n",
    "    df[hrcol].loc[(df[hrcol]<30)|(df[hrcol]>180)] = np.nan\n",
    "    pre_hr = df[hrcol].iloc[evt1ix - SEGLEN:evt1ix].mean(skipna=True)\n",
    "    pst_hr = df[hrcol].iloc[evt2ix: evt2ix+SEGLEN].mean(skipna=True)\n",
    "      \n",
    "      \n",
    "    # extract noninvasive systolic blood pressure, or continous systolic blood pressure measurement, alternatively.\n",
    "    pre_bp, pst_bp = np.nan, np.nan\n",
    "    df['NIBP_SBP'].loc[(df['NIBP_SBP']<40)|(df['NIBP_SBP']>210)] = np.nan\n",
    "    df['ART_SBP'].loc[(df['ART_SBP']<40)|(df['ART_SBP']>210)] = np.nan\n",
    "    \n",
    "    pre_bp = df['NIBP_SBP'].iloc[evt1ix - nibp_window:evt1ix].dropna()\n",
    "    if len(pre_bp)>0:\n",
    "        pre_bp = pre_bp.values[-1]\n",
    "    else:\n",
    "        pre_bp = df['ART_SBP'].iloc[evt1ix - nibp_window:evt1ix].dropna()\n",
    "        if len(pre_bp)>0:\n",
    "            pre_bp = pre_bp.values[-1]\n",
    "        else:\n",
    "            pre_bp = np.nan\n",
    "            \n",
    "    pst_bp = df['NIBP_SBP'].iloc[evt2ix:evt2ix+nibp_window].dropna()\n",
    "    if len(pst_bp)>0:\n",
    "        pst_bp = pst_bp.values[-1]\n",
    "    else:       \n",
    "        pst_bp = df['ART_SBP'].iloc[evt2ix:evt2ix+nibp_window].dropna()\n",
    "        if len(pst_bp)>0:\n",
    "            pst_bp = pst_bp.values[-1]\n",
    "        else:\n",
    "            pst_bp = np.nan\n",
    "\n",
    "    hr_change = round((pst_hr - pre_hr) / (pre_hr+0.1) * 100, 2)\n",
    "    bp_change = round((pst_bp - pre_bp) / (pre_bp+0.1) * 100, 2)\n",
    "\n",
    "\n",
    "    row = {'vitalfile':file, 'evt1': round(evt1ix / SRATE / 60,1), 'evt2': round(evt2ix / SRATE / 60,1), 'intu_dur' : intudur,\\\n",
    "            'hr_change':hr_change, 'bp_change':bp_change}\n",
    "    prerow = row.copy()\n",
    "    prerow['hr'] = pre_hr\n",
    "    prerow['bp'] = pre_bp\n",
    "    prerow['timing'] = 0\n",
    "    \n",
    "    pstrow = row.copy()\n",
    "    pstrow['hr'] = pst_hr\n",
    "    pstrow['bp'] = pst_bp    \n",
    "    pstrow['timing'] = 1\n",
    "\n",
    "    predf = df.iloc[evt1ix - SEGLEN : evt1ix].mean(skipna=True)\n",
    "    pstdf = df.iloc[evt2ix : evt2ix + SEGLEN].mean(skipna=True)\n",
    "\n",
    "    for col in [remicol, ppfcol, 'BIS']:\n",
    "        try:\n",
    "            prerow[col]= round(predf[col], 2)\n",
    "        except: \n",
    "            prerow[col]= np.nan\n",
    "\n",
    "    for col in [remicol, ppfcol, 'BIS']:\n",
    "        try:\n",
    "            pstrow[col]= round(pstdf[col],2)\n",
    "        except: \n",
    "            pstrow[col]= np.nan\n",
    "\n",
    "    df[eegcol].loc[(df[eegcol]>100)|(df[eegcol]<-100)] = np.nan\n",
    "    \n",
    "    process_eeg(df[eegcol], evt1ix-prewindow, prewindow, SEGLEN, SLIDE, prerow)\n",
    "    process_eeg(df[eegcol], evt2ix, pstwindow, SEGLEN, SLIDE, pstrow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.850000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.049999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.700001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477256</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477257</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477258</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477259</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477260</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1477261 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0   1   2   3   4   5          6   7\n",
       "0       NaN NaN NaN NaN NaN NaN  22.850000 NaN\n",
       "1       NaN NaN NaN NaN NaN NaN  22.900000 NaN\n",
       "2       NaN NaN NaN NaN NaN NaN  23.049999 NaN\n",
       "3       NaN NaN NaN NaN NaN NaN  23.299999 NaN\n",
       "4       NaN NaN NaN NaN NaN NaN  23.700001 NaN\n",
       "...      ..  ..  ..  ..  ..  ..        ...  ..\n",
       "1477256 NaN NaN NaN NaN NaN NaN        NaN NaN\n",
       "1477257 NaN NaN NaN NaN NaN NaN        NaN NaN\n",
       "1477258 NaN NaN NaN NaN NaN NaN        NaN NaN\n",
       "1477259 NaN NaN NaN NaN NaN NaN        NaN NaN\n",
       "1477260 NaN NaN NaN NaN NaN NaN        NaN NaN\n",
       "\n",
       "[1477261 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tacrolimus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
